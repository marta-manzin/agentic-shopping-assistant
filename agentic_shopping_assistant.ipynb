{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marta-manzin/agentic-shopping-assistant/blob/main/agentic_shopping_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOnQyK7obg_s"
   },
   "source": [
    "# üõí Agentic Shopping Assistant\n",
    "\n",
    "This notebook will go through all the steps to create an agentic shopping assistant. \\\n",
    "We will:\n",
    "1. Connect to OpenAI\n",
    "2. Create a simple agent\n",
    "3. Create an MCP server\n",
    "4. Create an MCP client\n",
    "5. Create a LangGraph agent\n",
    "\n",
    "<br/>\n",
    "<img src=\"https://raw.githubusercontent.com/marta-manzin/agentic-shopping-assistant/main/images/assistant.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4irdiFHM8Nz7"
   },
   "source": [
    "# ‚öôÔ∏è Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBEKX8f4UE8F"
   },
   "source": [
    "Setup\n",
    "Before we start using OpenAI models, you need to set an API key. \\\n",
    "If you don't already have an key, you can generate one at: https://platform.openai.com/api-keys.\n",
    "\n",
    "Save the key as a Colab Secret variable called \"OPENAI_API_KEY\":\n",
    "1. Click on the key icon in the left bar menu.\n",
    "2. Click on `+ Add new secret`.\n",
    "3. Name the variable and paste the key in the value field.\n",
    "4. Enable notebook access.\n",
    "\n",
    "<br/>\n",
    "<img src=\"https://raw.githubusercontent.com/marta-manzin/agentic-shopping-assistant/main/images/colab_setup.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZxTvnYm8Q1O"
   },
   "source": [
    "Import the API key into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "id": "wF4xGJKnCta2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Detect if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Set API key based on environment\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "else:\n",
    "    # For local Jupyter: ensure OPENAI_API_KEY is set in your environment\n",
    "    if \"OPENAI_API_KEY\" not in os.environ:\n",
    "        print(\"Warning: OPENAI_API_KEY not found in environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "aIdi2xjLbWOX",
    "tags": []
   },
   "source": [
    "Then, make a test call to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvlxGVjz8S7l",
    "outputId": "b2aaf98b-2b2c-40d5-ccd1-a00aa112970a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM test: OK\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI()\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "# Test that the LLM is set up correctly\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say 'OK' if you can read this.\"}],\n",
    "    max_tokens=10\n",
    ")\n",
    "print(f\"LLM test: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ToWYG3qNDzH"
   },
   "source": [
    "# ü§ñ Creating an Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATPYxIUbIigj"
   },
   "source": [
    "In Python, a set is an unordered collection of unique elements. \\\n",
    "We will build an agent that adds and removes strings from a set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spVukIqXCta3"
   },
   "source": [
    "## Defining the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujra-LLDcaeP"
   },
   "source": [
    "The System Prompt gives context to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u2p8auWt_fGE"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that adds and removes strings from a set.\n",
    "\n",
    "You have access to tools that let you:\n",
    "1. Add a string, if it is not already in the set.\n",
    "2. Remove a string.\n",
    "3. Read all contents of the set.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwzdXKyycs0P"
   },
   "source": [
    "Here are the available tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eM8NowbiOv74"
   },
   "outputs": [],
   "source": [
    "MY_SET = set()\n",
    "\n",
    "def insertion_tool(s: str) -> str:\n",
    "  \"\"\"Tool: Add a string to a set.\"\"\"\n",
    "  try:\n",
    "    MY_SET.add(s)\n",
    "    return f\"Inserted '{s}'.\"\n",
    "  except Exception as ex:\n",
    "    return f\"Failed to insert '{s}'. {ex!r}\"\n",
    "\n",
    "def removal_tool(s: str) -> str:\n",
    "  \"\"\"Tool: Remove a string from a set.\"\"\"\n",
    "  try:\n",
    "    if s in MY_SET:\n",
    "      MY_SET.remove(s)\n",
    "      return f\"Removed '{s}'.\"\n",
    "    else:\n",
    "      return f\"'{s}' is not in the set.\"\n",
    "  except Exception as ex:\n",
    "    return f\"Failed to remove '{s}'. {ex!r}\"\n",
    "\n",
    "def get_set_tool() -> str:\n",
    "  \"\"\"Tool: Get the contents of the set.\"\"\"\n",
    "  try:\n",
    "    if MY_SET:\n",
    "      return f\"The set contains: {sorted(MY_SET)}\"\n",
    "    else:\n",
    "      return \"The set is empty.\"\n",
    "  except Exception as ex:\n",
    "    return f\"Failed to get set contents. {ex!r}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOlTPB1RcVDH"
   },
   "source": [
    "Provide a description of each tool to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "id": "qY3nlJhU-x7U",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools: list[dict] = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"insertion_tool\",\n",
    "            \"description\": \"Add a string to a set.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"s\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The string to be added.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"s\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"removal_tool\",\n",
    "            \"description\": \"Remove a string from a set.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"s\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The string to be removed.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"s\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_set_tool\",\n",
    "            \"description\": \"Get the contents of the set.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8kQzFCiCta4"
   },
   "source": [
    "## Calling a Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTe3UobJc8DF"
   },
   "source": [
    "If the LLM decides to run a tool, instead of responding with a message, it will respond with a `tool_call` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SF18feG0Cta4"
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "# Create a tool_call object that matches OpenAI's structure\n",
    "tool_call = SimpleNamespace(\n",
    "    id=\"call_abc123\",\n",
    "    function=SimpleNamespace(\n",
    "        name=\"insertion_tool\",\n",
    "        arguments='{\"s\":\"apple\"}'\n",
    "    ),\n",
    "    type=\"function\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4zTu3tVCta4"
   },
   "source": [
    "Extract the function name from the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "tK4k2o-RCta4",
    "outputId": "f367d7b9-cb61-4e09-b875-bc25a7e8a48c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'insertion_tool'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_name = tool_call.function.name\n",
    "function_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDQf5fivCta4"
   },
   "source": [
    "Parse the arguments from JSON string to dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBxnlx6mCta4",
    "outputId": "1977b224-8578-4f51-b509-74145a33576c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': 'apple'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "arguments = json.loads(tool_call.function.arguments)\n",
    "arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-690_gbRCta4"
   },
   "source": [
    "Important! Verify that the function is one of the allowed tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LqgqwiYCta4",
    "outputId": "ccccaafd-ee00-42bc-edb1-cb8cb5130317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'insertion_tool' is an allowed tool.\n"
     ]
    }
   ],
   "source": [
    "allowed_tool_names = [tool[\"function\"][\"name\"] for tool in tools]\n",
    "if function_name not in allowed_tool_names:\n",
    "    print(f\"Error: '{function_name}' is not an allowed tool.\")\n",
    "else:\n",
    "    print(f\"'{function_name}' is an allowed tool.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYTFBcSSCta5"
   },
   "source": [
    "Verify that the function exists and is callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADgC3flRCta5",
    "outputId": "8ca5db1c-0cd2-409d-a409-e4fedd0b0c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function insertion_tool exists.\n"
     ]
    }
   ],
   "source": [
    "tool_func = globals().get(function_name)\n",
    "if tool_func is None or not callable(tool_func):\n",
    "    print(f\"Unknown function: {function_name}\")\n",
    "else:\n",
    "    print(f\"Function {function_name} exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zwnwaw2XCta5"
   },
   "source": [
    "Call the function with the unpacked arguments and print its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "z_X6zu8cCta5",
    "outputId": "a85d21f4-c306-499a-f046-b5a92bff4372"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Inserted 'apple'.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MY_SET = set()\n",
    "\n",
    "response = tool_func(**arguments)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CxGK_p0Cta5"
   },
   "source": [
    "Combine all tool calling steps in one method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "id": "u5YkPNiU_iKR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def execute(tool_call) -> str:\n",
    "    \"\"\"Execute a tool call and return the result, if any.\"\"\"\n",
    "    # Extract the function name from the tool call\n",
    "    function_name = tool_call.function.name\n",
    "\n",
    "    # Parse the arguments from JSON string to dictionary\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    # Important! Verify that the function is one of the allowed tools\n",
    "    allowed_tool_names = [tool[\"function\"][\"name\"] for tool in tools]\n",
    "    if function_name not in allowed_tool_names:\n",
    "        return f\"Error: '{function_name}' is not an allowed tool.\"\n",
    "\n",
    "    # Verify that the function exists and is callable\n",
    "    tool_func = globals().get(function_name)\n",
    "    if tool_func is None or not callable(tool_func):\n",
    "        return f\"Unknown function: {function_name}\"\n",
    "\n",
    "    # Call the function with the unpacked arguments\n",
    "    response = tool_func(**arguments)\n",
    "\n",
    "    # Return the tool's response\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyOsu-4tleGP"
   },
   "source": [
    "## The agentic loop\n",
    "Instead of using a ready-made framework, the code below implements *direct orchestration*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydrbuU8oCta5"
   },
   "source": [
    "We want to build a `while True` loop with tool calls when the LLM requests it.  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/marta-manzin/agentic-shopping-assistant/main/images/agentic_flow.png\" width=\"600\">\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/marta-manzin/agentic-shopping-assistant/main/images/agentic_flow_1.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gixuOfxwCta5"
   },
   "source": [
    "`print_history` is a utility function that will display the LLM conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tt5WwgxACta5"
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_history(messages, width=70):\n",
    "    \"\"\"Pretty print messages history.\"\"\"\n",
    "    # For each message in the history\n",
    "    for i, msg in enumerate(messages):\n",
    "        print(f\"\\n[{i}] Role: {msg['role']}\")\n",
    "\n",
    "        # Display message text if present\n",
    "        if msg.get('content'):\n",
    "            for line in str(msg['content']).split('\\n'):\n",
    "                wrapped = textwrap.fill(line, width=width, initial_indent='    ', subsequent_indent='    ')\n",
    "                print(wrapped)\n",
    "\n",
    "        # Display tool calls if present\n",
    "        if msg.get('tool_calls'):\n",
    "            for tc in msg['tool_calls']:\n",
    "                func_name = tc.function.name\n",
    "                func_args = tc.function.arguments\n",
    "                print(f\"    üîß {func_name}({func_args})\")\n",
    "\n",
    "        # If this is an assistant message with no tool calls, show completion\n",
    "        if msg['role'] == 'assistant' and not msg.get('tool_calls'):\n",
    "            print(f\"\\n‚≠ê The resulting set is: {MY_SET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4h6eNk8Cta5"
   },
   "source": [
    "Initialize the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMH41c0dCta5",
    "outputId": "a38cfd83-34f5-4302-a6aa-4588b5559db4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0] Role: system\n",
      "\n",
      "    You are a helpful assistant that adds and removes strings from a\n",
      "    set.\n",
      "\n",
      "    You have access to tools that let you:\n",
      "    1. Add a string, if it is not already in the set.\n",
      "    2. Remove a string.\n",
      "    3. Read all contents of the set.\n",
      "\n",
      "\n",
      "[1] Role: user\n",
      "    Please add 'apples' to the set.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": SYSTEM_PROMPT\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Please add 'apples' to the set.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print_history(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0NHnlMuEg3-"
   },
   "source": [
    "Ask the agent what to do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2l5y9lDvEgGw",
    "outputId": "536e8279-7398-428d-cecc-752dfa6e1b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"call_8KFqldAiLjK6RoyVphVySyGJ\",\n",
      "    \"function\": {\n",
      "      \"arguments\": \"{\\\"s\\\":\\\"apples\\\"}\",\n",
      "      \"name\": \"insertion_tool\"\n",
      "    },\n",
      "    \"type\": \"function\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ").choices[0].message\n",
    "\n",
    "# Display the raw tool call in the agent's response\n",
    "tool_calls_data = [tc.model_dump() for tc in response.tool_calls]\n",
    "print(json.dumps(tool_calls_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35gElhhYCta5"
   },
   "source": [
    "Update the chat history with the agent's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWBZcuurCta5",
    "outputId": "987e4772-33d9-47b8-ab6f-a95e6df7ee9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0] Role: system\n",
      "\n",
      "    You are a helpful assistant that adds and removes strings from a\n",
      "    set.\n",
      "\n",
      "    You have access to tools that let you:\n",
      "    1. Add a string, if it is not already in the set.\n",
      "    2. Remove a string.\n",
      "    3. Read all contents of the set.\n",
      "\n",
      "\n",
      "[1] Role: user\n",
      "    Please add 'apples' to the set.\n",
      "\n",
      "[2] Role: assistant\n",
      "    üîß insertion_tool({\"s\":\"apples\"})\n"
     ]
    }
   ],
   "source": [
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response.content,\n",
    "    \"tool_calls\": response.tool_calls\n",
    "})\n",
    "\n",
    "print_history(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uudc001fCta6"
   },
   "source": [
    "Execute the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "9yMBxPNKCta6",
    "outputId": "2436a5fb-d632-4c78-8ca8-97e24b564256"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Inserted 'apples'.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MY_SET = set()\n",
    "\n",
    "outcome = execute(response.tool_calls[0])\n",
    "outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A949_DYhCta6"
   },
   "source": [
    "Append the outcome to the message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zc5xXr7yCta6",
    "outputId": "bb8ab3db-28ed-47be-8d08-ca65fea8818c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0] Role: system\n",
      "\n",
      "    You are a helpful assistant that adds and removes strings from a\n",
      "    set.\n",
      "\n",
      "    You have access to tools that let you:\n",
      "    1. Add a string, if it is not already in the set.\n",
      "    2. Remove a string.\n",
      "    3. Read all contents of the set.\n",
      "\n",
      "\n",
      "[1] Role: user\n",
      "    Please add 'apples' to the set.\n",
      "\n",
      "[2] Role: assistant\n",
      "    üîß insertion_tool({\"s\":\"apples\"})\n",
      "\n",
      "[3] Role: tool\n",
      "    Inserted 'apples'.\n"
     ]
    }
   ],
   "source": [
    "messages.append({\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": str(outcome)\n",
    "})\n",
    "print_history(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUm6RwSVCta6"
   },
   "source": [
    "Combine all direct orchestration steps into one method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "u4B9C8CKXmOm"
   },
   "outputs": [],
   "source": [
    "def submit_request(\n",
    "    user_prompt: str,\n",
    "    verbose: bool = True\n",
    "    ):\n",
    "    \"\"\"Submit a request to the agent and run any tools it calls.\"\"\"\n",
    "    # Initialize the chat history\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Ask the agent what to do next\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        ).choices[0].message\n",
    "\n",
    "        # Update the chat history with the agent's response\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response.content,\n",
    "            \"tool_calls\": response.tool_calls\n",
    "        })\n",
    "\n",
    "        # If agent did not call any tools, we are done\n",
    "        if not response.tool_calls:\n",
    "            if verbose:\n",
    "              print(f\"\\n‚≠ê The resulting set is: {MY_SET}\")\n",
    "            break\n",
    "\n",
    "        # Execute all tool calls\n",
    "        for tool_call in response.tool_calls:\n",
    "            if verbose:\n",
    "              print(f\"\\nüîß The agent is calling a tool: \"\n",
    "                  f\"{tool_call.function.name}\"\n",
    "                  f\"({json.loads(tool_call.function.arguments)})\")\n",
    "\n",
    "            # Append the outcome to the message history\n",
    "            outcome = execute(tool_call)\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": str(outcome)\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NF26AUcTeM9C"
   },
   "source": [
    "## Let's test the agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gcdl8b9sCta6"
   },
   "source": [
    "Submit a request to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnCP2npeeYev",
    "outputId": "c50026ad-91a0-4fba-fcd6-c24e722362a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß The agent is calling a tool: insertion_tool({'s': 'apples'})\n",
      "\n",
      "üîß The agent is calling a tool: insertion_tool({'s': 'oranges'})\n",
      "\n",
      "üîß The agent is calling a tool: insertion_tool({'s': 'pears'})\n",
      "\n",
      "‚≠ê The resulting set is: {'oranges', 'pears', 'apples'}\n"
     ]
    }
   ],
   "source": [
    "MY_SET = set()\n",
    "submit_request(\"Please add 'apples', 'oranges' and 'pears' to the set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyEnJNzACta6"
   },
   "source": [
    "Inspect the message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPrhpMTSbRZv",
    "outputId": "4b18e7cb-3fc2-473a-c824-16aaffc44e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß The agent is calling a tool: removal_tool({'s': 'oranges'})\n",
      "\n",
      "‚≠ê The resulting set is: {'pears', 'apples'}\n"
     ]
    }
   ],
   "source": [
    "submit_request(\"Please remove 'oranges' from the set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_P3GEVCNTQ6"
   },
   "source": [
    "# üóÑÔ∏è Creating an MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD6I4qqM3-K-"
   },
   "source": [
    "Create the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xem5Szb0AQqv",
    "outputId": "65527752-e529-4359-cc66-2300868a2f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Server created\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet mcp\n",
    "from mcp.server import Server\n",
    "from mcp.types import Tool, TextContent\n",
    "\n",
    "server = Server(\"set-server\")\n",
    "print(\"‚úì Server created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuRlZnAYATtj"
   },
   "source": [
    "Create an MCP wrapper for listing the available tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "R4RQ-E6QArjt",
    "outputId": "fb7b3801-2de5-4529-8af4-5e34cbe91d16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>list_tools</b><br/>async def list_tools() -&gt; list[Tool]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/tmp/ipython-input-1517282331.py</a>Return the list of available tools from our tools definition.</pre></div>"
      ],
      "text/plain": [
       "<function __main__.list_tools() -> list[mcp.types.Tool]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def list_tools() -> list[Tool]:\n",
    "    \"\"\"Return the list of available tools from our tools definition.\"\"\"\n",
    "    # Create an empty list to store MCP Tool objects\n",
    "    mcp_tools = []\n",
    "\n",
    "    # Convert each tool from our OpenAI format to MCP format\n",
    "    for tool_def in tools:\n",
    "        # Extract the function definition from the OpenAI tool format\n",
    "        func_def = tool_def[\"function\"]\n",
    "\n",
    "        # Create an MCP Tool object with the same information\n",
    "        mcp_tools.append(Tool(\n",
    "            name=func_def[\"name\"], # the function name\n",
    "            description=func_def[\"description\"], # what the tool does\n",
    "            inputSchema=func_def[\"parameters\"] # the JSON schema for parameters\n",
    "        ))\n",
    "\n",
    "    # Return the list of MCP Tool objects\n",
    "    return mcp_tools\n",
    "\n",
    "# Register the list_tools function with the server\n",
    "server.list_tools()(list_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NM4w_xtuAvHM"
   },
   "source": [
    "Create an MCP wrapper for executing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "ib0oaEEQBJp2",
    "outputId": "3d8eab95-2f81-4ab7-c129-ae076286c1fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>call_tool</b><br/>async def call_tool(name: str, arguments: dict) -&gt; list[TextContent]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/tmp/ipython-input-1280466409.py</a>Handle MCP tool calls by delegating to our existing tools.</pre></div>"
      ],
      "text/plain": [
       "<function __main__.call_tool(name: str, arguments: dict) -> list[mcp.types.TextContent]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "async def call_tool(name: str, arguments: dict) -> list[TextContent]:\n",
    "    \"\"\"Handle MCP tool calls by delegating to our existing tools.\"\"\"\n",
    "    # Convert MCP format to the format expected by execute()\n",
    "    function = SimpleNamespace(\n",
    "        name=name,\n",
    "        arguments=json.dumps(arguments)  # Convert dict to JSON string\n",
    "    )\n",
    "    tool_call = SimpleNamespace(function=function)\n",
    "\n",
    "    # Execute the tool using the existing execute() function\n",
    "    result = execute(tool_call)\n",
    "\n",
    "    # Convert result to MCP response format\n",
    "    return [TextContent(type=\"text\", text=str(result))]\n",
    "\n",
    "# Register the call_tool function with the server\n",
    "server.call_tool()(call_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_UTk9kMBXdv"
   },
   "source": [
    "Create a web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BJ57ifFcBbDx"
   },
   "outputs": [],
   "source": [
    "# FastAPI is a framework for building REST APIs\n",
    "%pip install --quiet fastapi\n",
    "from mcp.server.sse import SseServerTransport\n",
    "from fastapi import FastAPI, Request\n",
    "from fastapi.responses import Response\n",
    "\n",
    "# Create a FastAPI web application\n",
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uZFZ74lbRZx"
   },
   "source": [
    "Expose a `POST` endpoint, used to handle incoming tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Fp6yHN5Ihfsb"
   },
   "outputs": [],
   "source": [
    "# Create an SSE transport that will handle messages at the \"/messages\" path\n",
    "sse = SseServerTransport(\"/messages\")\n",
    "\n",
    "# Mount the POST handler for receiving messages\n",
    "# Clients send messages to http://host:port/messages\n",
    "app.mount(\"/messages\", sse.handle_post_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sisQuL_3hjSt"
   },
   "source": [
    "Expose a `GET` endpoint, used to establish the connection to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "7jti91XFhp1r"
   },
   "outputs": [],
   "source": [
    "async def handle_sse(request: Request):\n",
    "    \"\"\"Handle incoming SSE connections from MCP clients.\"\"\"\n",
    "    # Connect the SSE transport to get read/write streams\n",
    "    async with sse.connect_sse(\n",
    "        request.scope, request.receive, request._send\n",
    "    ) as (read_stream, write_stream):\n",
    "        # Run the MCP server with these streams\n",
    "        await server.run(\n",
    "            read_stream,\n",
    "            write_stream,\n",
    "            server.create_initialization_options()\n",
    "        )\n",
    "    return Response()\n",
    "\n",
    "# Register the GET endpoint with the FastAPI app\n",
    "# Clients connect to http://host:port/sse to establish SSE connection\n",
    "app.add_api_route(\"/sse\", handle_sse, methods=[\"GET\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkBalETRhvs7"
   },
   "source": [
    "Create a web server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "15bATOhDbRZx"
   },
   "outputs": [],
   "source": [
    "# Uvicorn is a web server that handles HTTP requests and asynchronous code\n",
    "%pip install --quiet uvicorn\n",
    "import threading\n",
    "import uvicorn\n",
    "import sys\n",
    "\n",
    "# The port number where the server will listen\n",
    "server_port = 12345\n",
    "\n",
    "def run_server():\n",
    "    \"\"\"Run the uvicorn server. This will be called in a background thread.\"\"\"\n",
    "    try:\n",
    "        # Start the server on all network interfaces (0.0.0.0) at the specified port\n",
    "        uvicorn.run(app, host=\"0.0.0.0\", port=server_port, log_level=\"warning\")\n",
    "    except Exception as e:\n",
    "        # Print any errors to stderr\n",
    "        print(f\"‚úó Server error: {e}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ud3_4UyEqxGx"
   },
   "source": [
    "Start server in a background thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9XB_7tbqzR5",
    "outputId": "537dd1ab-ffef-4b33-c825-1d832faacbbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MCP HTTP server on port 12345 in background...\n",
      "Server available at http://127.0.0.1:12345/sse\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "server_thread = threading.Thread(\n",
    "    target=run_server,\n",
    "    daemon=True  # thread will automatically stop when main program exits\n",
    ")\n",
    "\n",
    "print(f\"Starting MCP HTTP server on port {server_port} in background...\")\n",
    "server_thread.start()\n",
    "time.sleep(3) # wait 3 seconds for the server to start\n",
    "\n",
    "# Confirm server URL\n",
    "server_url = f\"http://127.0.0.1:{server_port}/sse\"\n",
    "print(f\"Server available at {server_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5o2YO2EFbRZx"
   },
   "source": [
    "# ü§ù Creating an MCP Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDVifXoobRZx"
   },
   "source": [
    "List available tools on the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1Sp7zRqBjV7",
    "outputId": "7a529e3b-00a4-4d13-c5c4-500c70020fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools: ['insertion_tool', 'removal_tool', 'get_set_tool']\n"
     ]
    }
   ],
   "source": [
    "from mcp import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "\n",
    "# Utility function to list tools\n",
    "async def list_mcp_tools():\n",
    "    \"\"\"Helper function to list available MCP tools.\"\"\"\n",
    "    async with sse_client(server_url) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            available_tools = await session.list_tools()\n",
    "            return available_tools\n",
    "\n",
    "available_tools = await list_mcp_tools()\n",
    "print(\"Available tools:\", [t.name for t in available_tools.tools])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFaCBlNrbRZx"
   },
   "source": [
    "Test each tool, starting with an empty set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "pZZJlvO6bRZx"
   },
   "outputs": [],
   "source": [
    "# Utility function to call a tool\n",
    "async def call_mcp_tool(tool_name: str, arguments: dict = {}):\n",
    "    \"\"\"Helper function to call an MCP tool.\"\"\"\n",
    "    async with sse_client(server_url) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            result = await session.call_tool(tool_name, arguments)\n",
    "            return result\n",
    "\n",
    "MY_SET = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfWWFltkqTUY"
   },
   "source": [
    "Add \"cherries\" to the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFpcTtJWB2-W",
    "outputId": "d7c009f8-26a4-48e7-cfb6-daab740c08a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 'cherries'.\n"
     ]
    }
   ],
   "source": [
    "result = await call_mcp_tool(\"insertion_tool\", {\"s\": \"cherries\"})\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_1bHYz7qTUY"
   },
   "source": [
    "Attempt to remove \"bananas\" from the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VnEligIZB4qz",
    "outputId": "86b674bc-f223-4e93-9677-7aaabf72fd4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bananas' is not in the set.\n"
     ]
    }
   ],
   "source": [
    "result = await call_mcp_tool(\"removal_tool\", {\"s\": \"bananas\"})\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD7tlsbCqTUY"
   },
   "source": [
    "Read all contents of the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sypt2eJNbRZx",
    "outputId": "d6214be0-6491-4018-dbdd-71fe20fdf417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The set contains: ['cherries']\n"
     ]
    }
   ],
   "source": [
    "result = await call_mcp_tool(\"get_set_tool\")\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "hhA0L8dUNvYJ",
    "tags": []
   },
   "source": [
    "# üß† Orchestration with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrIbDfYJN3y0",
    "outputId": "79e8d300-8dcd-4cec-ec68-63699a7d7586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/102.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m475.3/475.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade \"langchain\" \"langchain-openai\" \"langgraph\" \"langchain-mcp-adapters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true,
    "id": "5x5y8R-nkMrq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# Create MCP client that connects to your set-server\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"set-server\": {\n",
    "            \"transport\": \"sse\",\n",
    "            \"url\": f\"http://localhost:{server_port}/sse\",\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5fQ4TDPqTUY"
   },
   "source": [
    "Get available tools from the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "9LLjQytBCta8",
    "outputId": "d4c7454a-1a8c-41e9-a4b6-aa329b6eb030",
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- insertion_tool: Add a string to a set.\n",
      "- removal_tool: Remove a string from a set.\n",
      "- get_set_tool: Get the contents of the set.\n"
     ]
    }
   ],
   "source": [
    "tools_from_mcp = await client.get_tools()\n",
    "\n",
    "for tool in tools_from_mcp:\n",
    "    print(f\"- {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a LangGraph agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "agent_executor = create_agent(\n",
    "    ChatOpenAI(model=\"gpt-4o\", temperature=0),\n",
    "    tools_from_mcp,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function calls the LangGraph agent and prints the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "JvVsa-VmCta8",
    "outputId": "d0f6cad9-c1e5-4e1f-95bc-c5a2976bc9fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def submit_langgraph_request(user_prompt: str, verbose: bool = True):\n",
    "    \"\"\"Submit a request to the LangGraph agent and display the conversation.\"\"\"\n",
    "    from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "    \n",
    "    # Run the agent with the system prompt and user's prompt\n",
    "    result = await agent_executor.ainvoke({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Display the conversation if verbose\n",
    "    if verbose:\n",
    "        for message in result['messages']:\n",
    "\n",
    "            # Print user message\n",
    "            if isinstance(message, HumanMessage):\n",
    "                print(\"\\nüë§ User: \" + message.content)\n",
    "\n",
    "            # Print agent message\n",
    "            elif isinstance(message, AIMessage):\n",
    "                if message.content:\n",
    "                    print(\"\\nü§ñ Agent: \" + message.content)\n",
    "\n",
    "            # Print tool action\n",
    "            elif isinstance(message, ToolMessage):\n",
    "                # Extract text from content (handle both string and list of dicts)\n",
    "                if isinstance(message.content, str):\n",
    "                    outcome_text = message.content\n",
    "                elif isinstance(message.content, list) and len(message.content) > 0:\n",
    "                    # Extract 'text' field from the first item if it's a dict\n",
    "                    outcome_text = message.content[0].get('text', str(message.content[0]))\n",
    "                else:\n",
    "                    outcome_text = str(message.content)\n",
    "                \n",
    "                print(f\"\\nüîß {message.name}: {outcome_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "editable": true,
    "id": "0eKr2OgVCta8",
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ User: Please add 'grapes', 'kiwi', and 'mango' to the set. Then display the set.\n",
      "\n",
      "üîß insertion_tool: Inserted 'grapes'.\n",
      "\n",
      "üîß insertion_tool: Inserted 'kiwi'.\n",
      "\n",
      "üîß insertion_tool: Inserted 'mango'.\n",
      "\n",
      "üîß get_set_tool: The set contains: ['cherries', 'grapes', 'kiwi', 'mango']\n",
      "\n",
      "ü§ñ Agent: The set now contains: ['cherries', 'grapes', 'kiwi', 'mango'].\n"
     ]
    }
   ],
   "source": [
    "await submit_langgraph_request(\"Please add 'grapes', 'kiwi', and 'mango' to the set. Then display the set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "<input type=\"checkbox\"> Add a web search tool for the LangGraph agent \\\n",
    "<input type=\"checkbox\"> Add a human-in-the-loop tool for the LangGraph agent \\\n",
    "<input type=\"checkbox\"> Add support for item quantities (eg. 3 apples) \\\n",
    "<input type=\"checkbox\"> Add a short section on recipe creation, to demonstrate the agent's features \\\n",
    "<input type=\"checkbox\"> Add an agent design exercise, where we prompt audiences to draw a diagram \\\n",
    "<input type=\"checkbox\"> Potentially add a short section on context management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßπ Cleanup\n",
    "\n",
    "Stop the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "JvVsa-VmCta8",
    "outputId": "d0f6cad9-c1e5-4e1f-95bc-c5a2976bc9fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Kill any process running uvicorn on our server port\n",
    "!pkill -f \"uvicorn.*{server_port}\"\n",
    "print(\"‚úì Server stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "0eKr2OgVCta8",
    "tags": [
     "active-ipynb"
    ]
   },
   "source": [
    "# Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "H4N9Oqg7No6i",
    "tags": []
   },
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "tags,id,outputId,raw_mimetype,colab_type,-editable,-slideshow,-colab",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
