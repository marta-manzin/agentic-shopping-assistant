{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marta-manzin/agentic-shopping-assistant/blob/main/agentic_shopping_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOnQyK7obg_s"
   },
   "source": [
    "# üõí Agentic Shopping Assistant\n",
    "\n",
    "This notebook will go through all the steps to create an agentic shopping assistant. \\\n",
    "We will:\n",
    "1. Connect to OpenAI\n",
    "2. Create a simple agent\n",
    "3. Create an MCP server\n",
    "4. Create an MCP client\n",
    "5. Create a LangGraph agent\n",
    "\n",
    "<br/>\n",
    "<img src=\"https://raw.githubusercontent.com/marta-manzin/agentic-shopping-assistant/main/images/assistant.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4irdiFHM8Nz7"
   },
   "source": [
    "# ‚öôÔ∏è Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBEKX8f4UE8F"
   },
   "source": [
    "Setup\n",
    "Before we start using OpenAI models, you need to set an API key. \\\n",
    "If you don't already have an key, you can generate one at: https://platform.openai.com/api-keys.\n",
    "\n",
    "Save the key as a Colab Secret variable called \"OPENAI_API_KEY\":\n",
    "1. Click on the key icon in the left bar menu.\n",
    "2. Click on `+ Add new secret`.\n",
    "3. Name the variable and paste the key in the value field.\n",
    "4. Enable notebook access.\n",
    "\n",
    "<br/>\n",
    "<img src=\"https://raw.githubusercontent.com/marta-manzin/agentic-shopping-assistant/main/images/colab_setup.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZxTvnYm8Q1O"
   },
   "source": [
    "Import the API key into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "wF4xGJKnCta2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Detect if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Set API key based on environment\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "else:\n",
    "    # For local Jupyter: ensure OPENAI_API_KEY is set in your environment\n",
    "    if \"OPENAI_API_KEY\" not in os.environ:\n",
    "        print(\"Warning: OPENAI_API_KEY not found in environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "aIdi2xjLbWOX",
    "tags": []
   },
   "source": [
    "Then, make a test call to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvlxGVjz8S7l",
    "outputId": "67e9f4bb-8817-4ed2-f6c8-f4c16618e290"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "client = openai.OpenAI()\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "# Test that the LLM is set up correctly\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say 'OK' if you can read this.\"}],\n",
    "    max_tokens=10\n",
    ")\n",
    "print(f\"LLM test: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ToWYG3qNDzH"
   },
   "source": [
    "# ü§ñ Creating an Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATPYxIUbIigj"
   },
   "source": [
    "In Python, a set is an unordered collection of unique elements. \\\n",
    "We will build an agent that adds and removes strings from a set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spVukIqXCta3"
   },
   "source": [
    "## Defining the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujra-LLDcaeP"
   },
   "source": [
    "The System Prompt gives context to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2p8auWt_fGE"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that adds and removes strings from a set.\n",
    "\n",
    "You have access to tools that let you:\n",
    "1. Add a string, if it is not already in the set.\n",
    "2. Remove a string.\n",
    "3. Read all contents of the set.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwzdXKyycs0P"
   },
   "source": [
    "Here are the available tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eM8NowbiOv74"
   },
   "outputs": [],
   "source": [
    "MY_SET = set()\n",
    "\n",
    "def insertion_tool(s: str) -> str:\n",
    "  \"\"\"Tool: Add a string to a set.\"\"\"\n",
    "  try:\n",
    "    MY_SET.add(s)\n",
    "    return f\"Inserted '{s}'.\"\n",
    "  except Exception as ex:\n",
    "    return f\"Failed to insert '{s}'. {ex!r}\"\n",
    "\n",
    "def removal_tool(s: str) -> str:\n",
    "  \"\"\"Tool: Remove a string from a set.\"\"\"\n",
    "  try:\n",
    "    if s in MY_SET:\n",
    "      MY_SET.remove(s)\n",
    "      return f\"Removed '{s}'.\"\n",
    "    else:\n",
    "      return f\"'{s}' is not in the set.\"\n",
    "  except Exception as ex:\n",
    "    return f\"Failed to remove '{s}'. {ex!r}\"\n",
    "\n",
    "def get_set_tool() -> str:\n",
    "  \"\"\"Tool: Get the contents of the set.\"\"\"\n",
    "  try:\n",
    "    if MY_SET:\n",
    "      return f\"The set contains: {sorted(MY_SET)}\"\n",
    "    else:\n",
    "      return \"The set is empty.\"\n",
    "  except Exception as ex:\n",
    "    return f\"Failed to get set contents. {ex!r}\"\n",
    "\n",
    "tool_map = {\n",
    "    \"insertion_tool\": insertion_tool,\n",
    "    \"removal_tool\": removal_tool,\n",
    "    \"get_set_tool\": get_set_tool\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOlTPB1RcVDH"
   },
   "source": [
    "Provide a description of each tool to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "qY3nlJhU-x7U",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools: list[dict] = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"insertion_tool\",\n",
    "            \"description\": \"Add a string to a set.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"s\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The string to be added.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"s\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"removal_tool\",\n",
    "            \"description\": \"Remove a string from a set.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"s\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The string to be removed.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"s\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_set_tool\",\n",
    "            \"description\": \"Get the contents of the set.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8kQzFCiCta4"
   },
   "source": [
    "## Calling a Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTe3UobJc8DF"
   },
   "source": [
    "If the LLM decides to run a tool, instead of responding with a message, it will respond with a `tool_call` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF18feG0Cta4"
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "# Create a tool_call object that matches OpenAI's structure\n",
    "tool_call = SimpleNamespace(\n",
    "    id=\"call_abc123\",\n",
    "    function=SimpleNamespace(\n",
    "        name=\"insertion_tool\",\n",
    "        arguments='{\"s\":\"apple\"}'\n",
    "    ),\n",
    "    type=\"function\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4zTu3tVCta4"
   },
   "source": [
    "Extract the function name from the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "tK4k2o-RCta4",
    "outputId": "2ccce342-54f0-4b38-c8af-d34c3b5336bd"
   },
   "outputs": [],
   "source": [
    "function_name = tool_call.function.name\n",
    "function_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDQf5fivCta4"
   },
   "source": [
    "Parse the arguments from JSON string to dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBxnlx6mCta4",
    "outputId": "70c253ce-8e3d-4b72-f90d-11d7cddecfa5"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "arguments = json.loads(tool_call.function.arguments)\n",
    "arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-690_gbRCta4"
   },
   "source": [
    "Important! Verify that the function is one of the allowed tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LqgqwiYCta4",
    "outputId": "0f9b6349-af88-4212-b8a4-444379fcaa66"
   },
   "outputs": [],
   "source": [
    "allowed_tool_names = [tool[\"function\"][\"name\"] for tool in tools]\n",
    "if function_name not in allowed_tool_names:\n",
    "    print(f\"Error: '{function_name}' is not an allowed tool.\")\n",
    "else:\n",
    "    print(f\"'{function_name}' is an allowed tool.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYTFBcSSCta5"
   },
   "source": [
    "Verify that the function exists and is callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADgC3flRCta5",
    "outputId": "c444dd48-e7b6-44e0-cab4-c4e5fd637233"
   },
   "outputs": [],
   "source": [
    "tool_func = tool_map[function_name]\n",
    "if tool_func is None or not callable(tool_func):\n",
    "    print(f\"Unknown function: {function_name}\")\n",
    "else:\n",
    "    print(f\"Function {function_name} exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zwnwaw2XCta5"
   },
   "source": [
    "Call the function with the unpacked arguments and print its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "z_X6zu8cCta5",
    "outputId": "81b062f5-5b28-43ce-e16b-c54583502d2d"
   },
   "outputs": [],
   "source": [
    "MY_SET = set()\n",
    "\n",
    "response = tool_func(**arguments)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CxGK_p0Cta5"
   },
   "source": [
    "Combine all tool calling steps in one method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "u5YkPNiU_iKR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def execute(tool_call) -> str:\n",
    "    \"\"\"Execute a tool call and return the result, if any.\"\"\"\n",
    "    # Extract the function name from the tool call\n",
    "    function_name = tool_call.function.name\n",
    "\n",
    "    # Parse the arguments from JSON string to dictionary\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    # Important! Verify that the function is one of the allowed tools\n",
    "    allowed_tool_names = [tool[\"function\"][\"name\"] for tool in tools]\n",
    "    if function_name not in allowed_tool_names:\n",
    "        return f\"Error: '{function_name}' is not an allowed tool.\"\n",
    "\n",
    "    # Verify that the function exists and is callable\n",
    "    tool_func = tool_map[function_name]\n",
    "    if tool_func is None or not callable(tool_func):\n",
    "        return f\"Unknown function: {function_name}\"\n",
    "\n",
    "    # Call the function with the unpacked arguments\n",
    "    response = tool_func(**arguments)\n",
    "\n",
    "    # Return the tool's response\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyOsu-4tleGP"
   },
   "source": [
    "## The agentic loop\n",
    "Instead of using a ready-made framework, the code below implements *direct orchestration*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydrbuU8oCta5"
   },
   "source": [
    "We want to build a `while True` loop with tool calls when the LLM requests it.  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/marta-manzin/agentic-shopping-assistant/main/images/agentic_flow.png\" width=\"600\">\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/marta-manzin/agentic-shopping-assistant/main/images/agentic_flow_1.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gixuOfxwCta5"
   },
   "source": [
    "`print_history` is a utility function that will display the LLM conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tt5WwgxACta5"
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_history(messages, width=70):\n",
    "    \"\"\"Pretty print messages history.\"\"\"\n",
    "    # For each message in the history\n",
    "    for i, msg in enumerate(messages):\n",
    "        print(f\"\\n[{i}] Role: {msg['role']}\")\n",
    "\n",
    "        # Display message text if present\n",
    "        if msg.get('content'):\n",
    "            for line in str(msg['content']).split('\\n'):\n",
    "                wrapped = textwrap.fill(line, width=width, initial_indent='    ', subsequent_indent='    ')\n",
    "                print(wrapped)\n",
    "\n",
    "        # Display tool calls if present\n",
    "        if msg.get('tool_calls'):\n",
    "            for tc in msg['tool_calls']:\n",
    "                func_name = tc.function.name\n",
    "                func_args = tc.function.arguments\n",
    "                print(f\"    üîß {func_name}({func_args})\")\n",
    "\n",
    "        # If this is an assistant message with no tool calls, show completion\n",
    "        if msg['role'] == 'assistant' and not msg.get('tool_calls'):\n",
    "            print(f\"\\n‚≠ê The resulting set is: {MY_SET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4h6eNk8Cta5"
   },
   "source": [
    "Initialize the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMH41c0dCta5",
    "outputId": "5cb00255-30c5-4905-a8ff-eb051f5e5cde"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": SYSTEM_PROMPT\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Please add 'apples' to the set.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print_history(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0NHnlMuEg3-"
   },
   "source": [
    "Ask the agent what to do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2l5y9lDvEgGw",
    "outputId": "e9f1e763-3275-4896-dfd1-dc876f8178b7"
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ").choices[0].message\n",
    "\n",
    "# Display the raw tool call in the agent's response\n",
    "tool_calls_data = [tc.model_dump() for tc in response.tool_calls]\n",
    "print(json.dumps(tool_calls_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35gElhhYCta5"
   },
   "source": [
    "Update the chat history with the agent's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWBZcuurCta5",
    "outputId": "e3a88fca-8c4d-468a-c119-688a01370d94"
   },
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response.content,\n",
    "    \"tool_calls\": response.tool_calls\n",
    "})\n",
    "\n",
    "print_history(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uudc001fCta6"
   },
   "source": [
    "Execute the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "9yMBxPNKCta6",
    "outputId": "dacd4bc3-8604-462e-f80a-51a07cd611c3"
   },
   "outputs": [],
   "source": [
    "MY_SET = set()\n",
    "\n",
    "outcome = execute(response.tool_calls[0])\n",
    "outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A949_DYhCta6"
   },
   "source": [
    "Append the outcome to the message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zc5xXr7yCta6",
    "outputId": "c822b78c-db83-4360-a31f-4d11078831d5"
   },
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": str(outcome)\n",
    "})\n",
    "print_history(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUm6RwSVCta6"
   },
   "source": [
    "Combine all direct orchestration steps into one method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4B9C8CKXmOm"
   },
   "outputs": [],
   "source": [
    "def submit_request(\n",
    "    user_prompt: str,\n",
    "    verbose: bool = True\n",
    "    ):\n",
    "    \"\"\"Submit a request to the agent and run any tools it calls.\"\"\"\n",
    "    # Initialize the chat history\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Ask the agent what to do next\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        ).choices[0].message\n",
    "\n",
    "        # Update the chat history with the agent's response\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response.content,\n",
    "            \"tool_calls\": response.tool_calls\n",
    "        })\n",
    "\n",
    "        # If agent did not call any tools, we are done\n",
    "        if not response.tool_calls:\n",
    "            if verbose:\n",
    "              print(f\"\\n‚≠ê The resulting set is: {MY_SET}\")\n",
    "            break\n",
    "\n",
    "        # Execute all tool calls\n",
    "        for tool_call in response.tool_calls:\n",
    "            if verbose:\n",
    "              print(f\"\\nüîß The agent is calling a tool: \"\n",
    "                  f\"{tool_call.function.name}\"\n",
    "                  f\"({json.loads(tool_call.function.arguments)})\")\n",
    "\n",
    "            # Append the outcome to the message history\n",
    "            outcome = execute(tool_call)\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": str(outcome)\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NF26AUcTeM9C"
   },
   "source": [
    "## Let's test the agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gcdl8b9sCta6"
   },
   "source": [
    "Submit a request to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnCP2npeeYev",
    "outputId": "86597343-6cad-44e9-d80f-b9fa1e6acc08"
   },
   "outputs": [],
   "source": [
    "MY_SET = set()\n",
    "submit_request(\"Please add 'apples', 'oranges' and 'pears' to the set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyEnJNzACta6"
   },
   "source": [
    "Inspect the message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPrhpMTSbRZv",
    "outputId": "c486165f-8c90-486a-d9fd-e8f8598d4804"
   },
   "outputs": [],
   "source": [
    "submit_request(\"Please remove 'oranges' from the set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_P3GEVCNTQ6"
   },
   "source": [
    "# üóÑÔ∏è Creating an MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD6I4qqM3-K-"
   },
   "source": [
    "Create the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xem5Szb0AQqv",
    "outputId": "49b80be2-4b30-4bbb-f700-1d194fc8efe3"
   },
   "outputs": [],
   "source": [
    "%pip install --quiet mcp\n",
    "from mcp.server import Server\n",
    "from mcp.types import Tool, TextContent\n",
    "\n",
    "server = Server(\"set-server\")\n",
    "print(\"‚úì Server created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuRlZnAYATtj"
   },
   "source": [
    "Create an MCP wrapper for listing the available tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "R4RQ-E6QArjt",
    "outputId": "3479efd3-0b10-44d1-9168-41513305129b"
   },
   "outputs": [],
   "source": [
    "async def list_tools() -> list[Tool]:\n",
    "    \"\"\"Return the list of available tools from our tools definition.\"\"\"\n",
    "    # Create an empty list to store MCP Tool objects\n",
    "    mcp_tools = []\n",
    "\n",
    "    # Convert each tool from our OpenAI format to MCP format\n",
    "    for tool_def in tools:\n",
    "        # Extract the function definition from the OpenAI tool format\n",
    "        func_def = tool_def[\"function\"]\n",
    "\n",
    "        # Create an MCP Tool object with the same information\n",
    "        mcp_tools.append(Tool(\n",
    "            name=func_def[\"name\"], # the function name\n",
    "            description=func_def[\"description\"], # what the tool does\n",
    "            inputSchema=func_def[\"parameters\"] # the JSON schema for parameters\n",
    "        ))\n",
    "\n",
    "    # Return the list of MCP Tool objects\n",
    "    return mcp_tools\n",
    "\n",
    "# Register the list_tools function with the server\n",
    "server.list_tools()(list_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NM4w_xtuAvHM"
   },
   "source": [
    "Create an MCP wrapper for executing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "ib0oaEEQBJp2",
    "outputId": "a82a62d2-5cca-433c-b8a7-1f5995059992"
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "async def call_tool(name: str, arguments: dict) -> list[TextContent]:\n",
    "    \"\"\"Handle MCP tool calls by delegating to our existing tools.\"\"\"\n",
    "    # Convert MCP format to the format expected by execute()\n",
    "    function = SimpleNamespace(\n",
    "        name=name,\n",
    "        arguments=json.dumps(arguments)  # Convert dict to JSON string\n",
    "    )\n",
    "    tool_call = SimpleNamespace(function=function)\n",
    "\n",
    "    # Execute the tool using the existing execute() function\n",
    "    result = execute(tool_call)\n",
    "\n",
    "    # Convert result to MCP response format\n",
    "    return [TextContent(type=\"text\", text=str(result))]\n",
    "\n",
    "# Register the call_tool function with the server\n",
    "server.call_tool()(call_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_UTk9kMBXdv"
   },
   "source": [
    "Create a web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJ57ifFcBbDx"
   },
   "outputs": [],
   "source": [
    "# FastAPI is a framework for building REST APIs\n",
    "%pip install --quiet fastapi\n",
    "from mcp.server.sse import SseServerTransport\n",
    "from fastapi import FastAPI, Request\n",
    "from fastapi.responses import Response\n",
    "\n",
    "# Create a FastAPI web application\n",
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uZFZ74lbRZx"
   },
   "source": [
    "Expose a `POST` endpoint, used to handle incoming tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fp6yHN5Ihfsb"
   },
   "outputs": [],
   "source": [
    "# Create an SSE transport that will handle messages at the \"/messages\" path\n",
    "sse = SseServerTransport(\"/messages\")\n",
    "\n",
    "# Mount the POST handler for receiving messages\n",
    "# Clients send messages to http://host:port/messages\n",
    "app.mount(\"/messages\", sse.handle_post_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sisQuL_3hjSt"
   },
   "source": [
    "Expose a `GET` endpoint, used to establish the connection to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jti91XFhp1r"
   },
   "outputs": [],
   "source": [
    "async def handle_sse(request: Request):\n",
    "    \"\"\"Handle incoming SSE connections from MCP clients.\"\"\"\n",
    "    # Connect the SSE transport to get read/write streams\n",
    "    async with sse.connect_sse(\n",
    "        request.scope, request.receive, request._send\n",
    "    ) as (read_stream, write_stream):\n",
    "        # Run the MCP server with these streams\n",
    "        await server.run(\n",
    "            read_stream,\n",
    "            write_stream,\n",
    "            server.create_initialization_options()\n",
    "        )\n",
    "    return Response()\n",
    "\n",
    "# Register the GET endpoint with the FastAPI app\n",
    "# Clients connect to http://host:port/sse to establish SSE connection\n",
    "app.add_api_route(\"/sse\", handle_sse, methods=[\"GET\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkBalETRhvs7"
   },
   "source": [
    "Create a web server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15bATOhDbRZx"
   },
   "outputs": [],
   "source": [
    "# Uvicorn is a web server that handles HTTP requests and asynchronous code\n",
    "%pip install --quiet uvicorn psutil\n",
    "\n",
    "import uvicorn, time, atexit, os, psutil\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "class ServerManager:\n",
    "    _process = None\n",
    "\n",
    "    @classmethod\n",
    "    def _get_pid_on_port(cls, port):\n",
    "        \"\"\"Helper to find the PID of any process listening on the specified port.\"\"\"\n",
    "        for conn in psutil.net_connections(kind='inet'):\n",
    "            if conn.laddr.port == port and conn.status == 'LISTEN':\n",
    "                # Ensure we don't return the current Jupyter Kernel's PID\n",
    "                if conn.pid != os.getpid():\n",
    "                    return conn.pid\n",
    "        return None\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def start(cls, app_obj, port):\n",
    "        \"\"\"Idempotent start: Runs the server if port is free, otherwise informs the user.\"\"\"\n",
    "        existing_pid = cls._get_pid_on_port(port)\n",
    "        \n",
    "        if existing_pid:\n",
    "            print(f\"Server is already running (PID {existing_pid}) at http://127.0.0.1:{port}\")\n",
    "            return\n",
    "\n",
    "        # Create and start the server in a separate background process\n",
    "        cls._process = Process(\n",
    "            target=uvicorn.run, \n",
    "            args=(app_obj,), \n",
    "            kwargs={'host': \"0.0.0.0\", 'port': port, 'log_level': \"warning\"}, \n",
    "            daemon=True\n",
    "        )\n",
    "        cls._process.start()\n",
    "        \n",
    "        # Wait to confirm the process stayed alive during startup\n",
    "        time.sleep(3)\n",
    "        if cls._process.is_alive():\n",
    "            print(f\"Server started (PID {cls._process.pid}) at http://127.0.0.1:{port}\")\n",
    "        else:\n",
    "            print(\"Server failed to start.\")\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def stop(cls, port):\n",
    "        \"\"\"Idempotent stop: Requests shutdown and waits for the port to clear.\"\"\"\n",
    "        pid = cls._get_pid_on_port(port)\n",
    "        if not pid:\n",
    "            print(f\"Port {port} is already clear.\")\n",
    "        else:\n",
    "            try:\n",
    "                proc = psutil.Process(pid)\n",
    "                proc.terminate()\n",
    "                # Return immediately when process dies (max 2 seconds)\n",
    "                proc.wait(timeout=2)\n",
    "                print(f\"Server (PID {pid}) stopped.\")\n",
    "            except psutil.TimeoutExpired:\n",
    "                print(f\"Server (PID {pid}) is taking a long time to exit.\")\n",
    "        \n",
    "        cls._process = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the web server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "server_port = 12345\n",
    "\n",
    "# Execute Start\n",
    "ServerManager.start(app, server_port)\n",
    "server_url = f\"http://127.0.0.1:{server_port}/sse\"\n",
    "\n",
    "# Register automatic cleanup for when the kernel or script exits\n",
    "atexit.register(lambda: ServerManager.stop(server_port));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5o2YO2EFbRZx"
   },
   "source": [
    "# ü§ù Creating an MCP Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDVifXoobRZx"
   },
   "source": [
    "List available tools on the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1Sp7zRqBjV7",
    "outputId": "579d14e4-5664-4c3d-cdcc-ce3a4243081b"
   },
   "outputs": [],
   "source": [
    "from mcp import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "\n",
    "# Utility function to list tools\n",
    "async def list_mcp_tools():\n",
    "    \"\"\"Helper function to list available MCP tools.\"\"\"\n",
    "    async with sse_client(server_url) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            available_tools = await session.list_tools()\n",
    "            return available_tools\n",
    "\n",
    "available_tools = await list_mcp_tools()\n",
    "print(\"Available tools:\", [t.name for t in available_tools.tools])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFaCBlNrbRZx"
   },
   "source": [
    "Test each tool, starting with an empty set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZZJlvO6bRZx"
   },
   "outputs": [],
   "source": [
    "# Utility function to call a tool\n",
    "async def call_mcp_tool(tool_name: str, arguments: dict = {}):\n",
    "    \"\"\"Helper function to call an MCP tool.\"\"\"\n",
    "    async with sse_client(server_url) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            result = await session.call_tool(tool_name, arguments)\n",
    "            return result\n",
    "\n",
    "MY_SET = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfWWFltkqTUY"
   },
   "source": [
    "Add \"cherries\" to the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFpcTtJWB2-W",
    "outputId": "351bae4d-fc1b-4d96-b38f-6be9a9ace111"
   },
   "outputs": [],
   "source": [
    "result = await call_mcp_tool(\"insertion_tool\", {\"s\": \"cherries\"})\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_1bHYz7qTUY"
   },
   "source": [
    "Attempt to remove \"bananas\" from the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VnEligIZB4qz",
    "outputId": "04a144af-bad4-4cd1-e522-5333b483d44b"
   },
   "outputs": [],
   "source": [
    "result = await call_mcp_tool(\"removal_tool\", {\"s\": \"bananas\"})\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD7tlsbCqTUY"
   },
   "source": [
    "Read all contents of the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sypt2eJNbRZx",
    "outputId": "f4f00117-41e3-4e5d-8a4e-7e16b84b517b"
   },
   "outputs": [],
   "source": [
    "result = await call_mcp_tool(\"get_set_tool\")\n",
    "print(result.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "hhA0L8dUNvYJ",
    "tags": []
   },
   "source": [
    "# üß† Orchestration with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrIbDfYJN3y0"
   },
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade \"langchain\" \"langchain-openai\" \"langgraph\" \"langchain-mcp-adapters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "5x5y8R-nkMrq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# Create MCP client that connects to your set-server\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"set-server\": {\n",
    "            \"transport\": \"sse\",\n",
    "            \"url\": f\"http://localhost:{server_port}/sse\",\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5fQ4TDPqTUY"
   },
   "source": [
    "Get available tools from the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "9LLjQytBCta8",
    "outputId": "a07af820-71f9-4807-ced5-ed3a1ba6c6f0",
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "tools_from_mcp = await client.get_tools()\n",
    "\n",
    "for tool in tools_from_mcp:\n",
    "    print(f\"- {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zpCPQ46KpOX"
   },
   "source": [
    "Create a LangGraph agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCIIxWdsKpOX"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "agent_executor = create_agent(\n",
    "    ChatOpenAI(model=\"gpt-4o\", temperature=0),\n",
    "    tools_from_mcp,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rePPfUYMKpOX"
   },
   "source": [
    "The following function calls the LangGraph agent and prints the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "JvVsa-VmCta8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def submit_langgraph_request(user_prompt: str, verbose: bool = True):\n",
    "    \"\"\"Submit a request to the LangGraph agent and display the conversation.\"\"\"\n",
    "    from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "    # Run the agent with the system prompt and user's prompt\n",
    "    result = await agent_executor.ainvoke({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Display the conversation if verbose\n",
    "    if verbose:\n",
    "        for message in result['messages']:\n",
    "\n",
    "            # Print user message\n",
    "            if isinstance(message, HumanMessage):\n",
    "                print(\"\\nüë§ User: \" + message.content)\n",
    "\n",
    "            # Print agent message\n",
    "            elif isinstance(message, AIMessage):\n",
    "                if message.content:\n",
    "                    print(\"\\nü§ñ Agent: \" + message.content)\n",
    "\n",
    "            # Print tool action\n",
    "            elif isinstance(message, ToolMessage):\n",
    "                # Extract text from content (handle both string and list of dicts)\n",
    "                if isinstance(message.content, str):\n",
    "                    outcome_text = message.content\n",
    "                elif isinstance(message.content, list) and len(message.content) > 0:\n",
    "                    # Extract 'text' field from the first item if it's a dict\n",
    "                    outcome_text = message.content[0].get('text', str(message.content[0]))\n",
    "                else:\n",
    "                    outcome_text = str(message.content)\n",
    "\n",
    "                print(f\"\\nüîß {message.name}: {outcome_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F94e0lJjKpOX"
   },
   "source": [
    "Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "0eKr2OgVCta8",
    "outputId": "4646eef0-7a53-4152-bf7a-0c24b75d72b6",
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "await submit_langgraph_request(\"Please add 'grapes', 'kiwi', and 'mango' to the set. Then display the set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üë©üèª‚Äçüíª Creating a Coding Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the outdated application looks like:\n",
    "https://dwoodlock.github.io/Metric-Treadmill-2017/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_DIRECTORY = \"./Metric-Treadmill-2017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the Metric-Treadmill-2017 repo\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "path = Path(\"./Metric-Treadmill-2017\")\n",
    "if path.exists() and path.is_dir(): shutil.rmtree(path)\n",
    "\n",
    "subprocess.run([\"git\", \"clone\", \"--quiet\", \"https://github.com/dwoodlock/Metric-Treadmill-2017.git\"], \n",
    "               check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that can interact with a computer using tools.\n",
    "\n",
    "You have access to the following tool:\n",
    "\n",
    "- bash: Execute bash commands on the system\n",
    "\n",
    "IMPORTANT: Every response must include:\n",
    "1. A THOUGHT section explaining your reasoning and what you plan to do\n",
    "2. A tool call to execute the bash command\n",
    "\n",
    "Your THOUGHT should be in the text of your response, followed by the tool call.\n",
    "Do not leave the text response empty - always explain your reasoning first.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user prompt template \n",
    "import httpx\n",
    "try:\n",
    "    response = httpx.get(\"https://raw.githubusercontent.com/marta-manzin/agentic-shopping-assistant/refs/heads/main/prompts/coding-user-prompt-template.txt\")\n",
    "    response.raise_for_status()\n",
    "    user_prompt_template = response.text\n",
    "except httpx.HTTPError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "print(\"\\n\".join(user_prompt_template.split(\"\\n\")[0:10]), \"\\n...\") # print first 10 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated the Tools - Add the Bash Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bash_tool(command: str) -> str:\n",
    "    \"\"\"Execute a bash command and return the result.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            command, shell=True, check=True,\n",
    "            capture_output=True, text=True,\n",
    "            cwd=CODE_DIRECTORY\n",
    "        )\n",
    "        return result.stdout if result.stdout else (\n",
    "            \"Command executed successfully with no output.\"\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error executing command: {e.stderr}\"\n",
    "\n",
    "bash_description = \"\"\"\n",
    "Execute bash commands on the system.\n",
    "\n",
    "## Useful command examples\n",
    "\n",
    "### Create a new file:\n",
    "cat <<'EOF' > newfile.py\n",
    "import numpy as np\n",
    "hello = \"world\"\n",
    "print(hello)\n",
    "EOF\n",
    "\n",
    "### Edit files with sed:\n",
    "IMPORTANT: You are on MacOS. Use `sed -i ''` instead of `sed -i`.\n",
    "\n",
    "# Replace all occurrences\n",
    "sed -i '' 's/old_string/new_string/g' filename.py\n",
    "\n",
    "# Replace only first occurrence\n",
    "sed -i '' 's/old_string/new_string/' filename.py\n",
    "\n",
    "# Replace first occurrence on line 1\n",
    "sed -i '' '1s/old_string/new_string/' filename.py\n",
    "\n",
    "# Replace all occurrences in lines 1-10\n",
    "sed -i '' '1,10s/old_string/new_string/g' filename.py\n",
    "\n",
    "### View file content:\n",
    "# View specific lines with numbers\n",
    "nl -ba filename.py | sed -n '10,20p'\n",
    "\n",
    "### Any other command you want to run\n",
    "You can run any bash command including ls, cat, find, python, etc.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Bash tool to our tools list.  (Check if it's been added already in case the cell is re-run)\n",
    "\n",
    "if 'bash_tool' not in [tool['function']['name'] for tool in tools]: \n",
    "    tools.append(\n",
    "{\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'bash_tool',\n",
    "        'description': bash_description,\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'command': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The bash command to execute.'\n",
    "                }\n",
    "            },\n",
    "            'required': ['command']\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it\n",
    "[tool['function']['name'] for tool in tools]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the User Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "I have a web app that I wrote many years ago that converts my running plans\n",
    "into a metric system if I find myself on a treadmill internationally.\n",
    "I‚Äôm concerned that it uses old libraries and old approaches and it‚Äôll just\n",
    "stop working one day.  Can you modernize this app for me.  I'd especially\n",
    "like you to eliminate unneeded and deprecated libraries and use modern\n",
    "language features and approaches.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the user request into the user prompt template to create the full prompt\n",
    "import platform\n",
    "enhanced_user_prompt = user_prompt_template.replace(\n",
    "    \"{{user-prompt}}\",\n",
    "    user_prompt\n",
    ").replace(\n",
    "    \"{{platform-uname}}\",\n",
    "    str(platform.uname()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a new LangGraph agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_from_mcp = await client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LangGraph agent using the updated tools\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent_executor = create_agent(\n",
    "    ChatOpenAI(model=\"gpt-4o\", temperature=0),\n",
    "    tools_from_mcp,\n",
    ")\n",
    "\n",
    "print(\"‚úì LangGraph agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "async def run_agent_with_progress():\n",
    "    iteration = 0\n",
    "    async for event in agent_executor.astream({\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": enhanced_user_prompt}]\n",
    "    }):\n",
    "        iteration = iteration + 1\n",
    "        print(\"-\" * 40, \"\\nIteration\", iteration)\n",
    "        if 'model' in event:\n",
    "            messages = event['model']['messages']\n",
    "        elif 'tools' in event:\n",
    "            messages = event['tools']['messages']\n",
    "        else:\n",
    "            assert False, \"Unimplemented event structure\"\n",
    "            \n",
    "        for message in messages:\n",
    "                if isinstance(message, AIMessage):\n",
    "                    if isinstance(type(message.content), str):\n",
    "                       print(\"AI: \\033[34m\" + message.content + \"\\033[0m\")\n",
    "                    elif isinstance(type(message.content), list):\n",
    "                        for content_block in message.content:\n",
    "                            if content_block['type'] == 'tool_use':\n",
    "                                print(\"AI: \\033[34m call\", content_block['name'], content_block['input'], \"\\033[0m\")\n",
    "                            elif content_block['type'] == 'text':\n",
    "                                print(\"AI: \\033[34m\", content_block['text'], \"\\033[0m\")\n",
    "                    else:\n",
    "                        assert False, \"Unimplemented message.content type\"\n",
    "                elif isinstance(message, ToolMessage):\n",
    "                    print(f\"Tool Result:\\n\\033[32m{message.content}\\033[0m\")\n",
    "                else:\n",
    "                    assert False, \"Unimplemented message type\"\n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Here we go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = await(run_agent_with_progress())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uN0bKTacKpOX"
   },
   "source": [
    "# Next Steps\n",
    "\n",
    "<input type=\"checkbox\"> Add a web search tool for the LangGraph agent \\\n",
    "<input type=\"checkbox\"> Add a human-in-the-loop tool for the LangGraph agent \\\n",
    "<input type=\"checkbox\"> Add support for item quantities (eg. 3 apples) \\\n",
    "<input type=\"checkbox\"> Add a short section on recipe creation, to demonstrate the agent's features \\\n",
    "<input type=\"checkbox\"> Add an agent design exercise, where we prompt audiences to draw a diagram \\\n",
    "<input type=\"checkbox\"> Potentially add a short section on context management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z0nRkovKpOX"
   },
   "source": [
    "# üßπ Cleanup\n",
    "\n",
    "Stop the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "KGD6y9bmKpOX",
    "outputId": "9c799bd0-9c26-4f71-eaea-d9a3dae656ef",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stop the MCP server using the ServerManager\n",
    "ServerManager.stop(server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "Mkv0P0DMKpOY",
    "tags": [
     "active-ipynb"
    ]
   },
   "source": [
    "# Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "H4N9Oqg7No6i",
    "tags": []
   },
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "tags,id,outputId,raw_mimetype,colab_type,-editable,-slideshow,-colab",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
