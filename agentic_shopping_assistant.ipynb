{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marta-manzin/agentic-shopping-assistant/blob/marta/agentic_shopping_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOnQyK7obg_s"
      },
      "source": [
        "# üõí Agentic Shopping Assistant\n",
        "\n",
        "This notebook will go through all the steps to create an agentic shopping assistant. \\\n",
        "We will:\n",
        "1. Connect to OpenAI\n",
        "2. Create a simple agent\n",
        "3. Create an MCP server\n",
        "4. Create a LangGraph agent\n",
        "\n",
        "<br/>\n",
        "<img src=\"https://github.com/marta-manzin/agentic-shopping-assistant/blob/marta/images/assistant.png?raw=1\" width=\"500\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4irdiFHM8Nz7"
      },
      "source": [
        "# ‚öôÔ∏è Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBEKX8f4UE8F"
      },
      "source": [
        "Setup\n",
        "Before we start using OpenAI models, you need to set an API key. \\\n",
        "If you don't already have an key, you can generate one at: https://platform.openai.com/api-keys. \\\n",
        "\n",
        "Save the key as a Colab Secret variable called \"OPENAI_API_KEY\":\n",
        "1. Click on the key icon in the left bar menu.\n",
        "2. Click on `+ Add new secret`.\n",
        "3. Name the variable and paste the key in the value field.\n",
        "4. Enable notebook access.\n",
        "\n",
        "<br/>\n",
        "<img src=\"https://github.com/marta-manzin/agentic-shopping-assistant/blob/marta/images/colab_setup.png?raw=1\" width=\"450\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZxTvnYm8Q1O"
      },
      "source": [
        "Import the API key into the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "wF4xGJKnCta2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Detect if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Set API key based on environment\n",
        "if IN_COLAB:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "else:\n",
        "    # For local Jupyter: ensure OPENAI_API_KEY is set in your environment\n",
        "    if \"OPENAI_API_KEY\" not in os.environ:\n",
        "        print(\"Warning: OPENAI_API_KEY not found in environment variables\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "aIdi2xjLbWOX",
        "tags": []
      },
      "source": [
        "Then, make a test call to OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvlxGVjz8S7l",
        "outputId": "6bf60b02-cba7-4772-9894-2061c766e800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM test: OK\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "client = openai.OpenAI()\n",
        "model = \"gpt-4o\"\n",
        "\n",
        "# Test that the LLM is set up correctly\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Say 'OK' if you can read this.\"}],\n",
        "    max_tokens=10\n",
        ")\n",
        "print(f\"LLM test: {response.choices[0].message.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ToWYG3qNDzH"
      },
      "source": [
        "# ü§ñ Creating an Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATPYxIUbIigj"
      },
      "source": [
        "In Python, a set is an unordered collection of unique elements. \\\n",
        "We will build an agent that adds and removes strings from a set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spVukIqXCta3"
      },
      "source": [
        "## Defining the tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujra-LLDcaeP"
      },
      "source": [
        "The System Prompt gives context to the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u2p8auWt_fGE"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a helpful assistant that adds and removes strings from a set.\n",
        "\n",
        "You have access to tools that let you:\n",
        "1. Add a string, if it is not already in the set.\n",
        "2. Remove a string.\n",
        "3. Read all contents of the set.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwzdXKyycs0P"
      },
      "source": [
        "Here are the available tools:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eM8NowbiOv74"
      },
      "outputs": [],
      "source": [
        "MY_SET = set()\n",
        "\n",
        "def insertion_tool(s: str) -> str:\n",
        "  \"\"\"Tool: Add a string to a set.\"\"\"\n",
        "  try:\n",
        "    MY_SET.add(s)\n",
        "    return f\"Inserted '{s}'.\"\n",
        "  except Exception as ex:\n",
        "    return f\"Failed to insert '{s}'. {ex!r}\"\n",
        "\n",
        "def removal_tool(s: str) -> str:\n",
        "  \"\"\"Tool: Remove a string from a set.\"\"\"\n",
        "  try:\n",
        "    if s in MY_SET:\n",
        "      MY_SET.remove(s)\n",
        "      return f\"Removed '{s}'.\"\n",
        "    else:\n",
        "      return f\"'{s}' is not in the set.\"\n",
        "  except Exception as ex:\n",
        "    return f\"Failed to remove '{s}'. {ex!r}\"\n",
        "\n",
        "def get_set_tool() -> str:\n",
        "  \"\"\"Tool: Get the contents of the set.\"\"\"\n",
        "  try:\n",
        "    if MY_SET:\n",
        "      return f\"The set contains: {sorted(MY_SET)}\"\n",
        "    else:\n",
        "      return \"The set is empty.\"\n",
        "  except Exception as ex:\n",
        "    return f\"Failed to get set contents. {ex!r}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOlTPB1RcVDH"
      },
      "source": [
        "Provide a description of each tool to the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "editable": true,
        "id": "qY3nlJhU-x7U",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools: list[dict] = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"insertion_tool\",\n",
        "            \"description\": \"Add a string to a set.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"s\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The string to be added.\"\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"s\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"removal_tool\",\n",
        "            \"description\": \"Remove a string from a set.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"s\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The string to be removed.\"\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"s\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_set_tool\",\n",
        "            \"description\": \"Get the contents of the set.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "                \"required\": []\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8kQzFCiCta4"
      },
      "source": [
        "## Calling a Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTe3UobJc8DF"
      },
      "source": [
        "If the LLM decides to run a tool, instead of responding with a message, it will respond with a `tool_call` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SF18feG0Cta4"
      },
      "outputs": [],
      "source": [
        "from types import SimpleNamespace\n",
        "\n",
        "# Create a tool_call object that matches OpenAI's structure\n",
        "tool_call = SimpleNamespace(\n",
        "    id=\"call_abc123\",\n",
        "    function=SimpleNamespace(\n",
        "        name=\"insertion_tool\",\n",
        "        arguments='{\"s\":\"apple\"}'\n",
        "    ),\n",
        "    type=\"function\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4zTu3tVCta4"
      },
      "source": [
        "Extract the function name from the tool call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tK4k2o-RCta4",
        "outputId": "df6e937d-b243-4130-bb59-9db820eec474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'insertion_tool'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "function_name = tool_call.function.name\n",
        "function_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDQf5fivCta4"
      },
      "source": [
        "Parse the arguments from JSON string to dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NBxnlx6mCta4",
        "outputId": "b6bfb341-299a-4e5a-a311-279bdb98fc06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'s': 'apple'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "arguments = json.loads(tool_call.function.arguments)\n",
        "arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-690_gbRCta4"
      },
      "source": [
        "Important! Verify that the function is one of the allowed tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0LqgqwiYCta4",
        "outputId": "d588152b-832e-4ca3-f9f4-f9553ccd0034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'insertion_tool' is an allowed tool.\n"
          ]
        }
      ],
      "source": [
        "allowed_tool_names = [tool[\"function\"][\"name\"] for tool in tools]\n",
        "if function_name not in allowed_tool_names:\n",
        "    print(f\"Error: '{function_name}' is not an allowed tool.\")\n",
        "else:\n",
        "    print(f\"'{function_name}' is an allowed tool.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYTFBcSSCta5"
      },
      "source": [
        "Verify that the function exists and is callable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ADgC3flRCta5",
        "outputId": "ddffed44-07cf-4b7c-d584-0d75c321ab61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function insertion_tool exists.\n"
          ]
        }
      ],
      "source": [
        "tool_func = globals().get(function_name)\n",
        "if tool_func is None or not callable(tool_func):\n",
        "    print(f\"Unknown function: {function_name}\")\n",
        "else:\n",
        "    print(f\"Function {function_name} exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwnwaw2XCta5"
      },
      "source": [
        "Call the function with the unpacked arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "z_X6zu8cCta5",
        "outputId": "46f4e14e-670c-408c-93af-30e7cc804522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Inserted 'apple'.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "MY_SET = set()\n",
        "\n",
        "response = tool_func(**arguments)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CxGK_p0Cta5"
      },
      "source": [
        "Combine all tool calling steps in one method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "editable": true,
        "id": "u5YkPNiU_iKR",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def execute(tool_call) -> str:\n",
        "    \"\"\"Execute a tool call and return the result, if any.\"\"\"\n",
        "    # Extract the function name from the tool call\n",
        "    function_name = tool_call.function.name\n",
        "\n",
        "    # Parse the arguments from JSON string to dictionary\n",
        "    arguments = json.loads(tool_call.function.arguments)\n",
        "\n",
        "    # Important! Verify that the function is one of the allowed tools\n",
        "    allowed_tool_names = [tool[\"function\"][\"name\"] for tool in tools]\n",
        "    if function_name not in allowed_tool_names:\n",
        "        return f\"Error: '{function_name}' is not an allowed tool.\"\n",
        "\n",
        "    # Verify that the function exists and is callable\n",
        "    tool_func = globals().get(function_name)\n",
        "    if tool_func is None or not callable(tool_func):\n",
        "        return f\"Unknown function: {function_name}\"\n",
        "\n",
        "    # Call the function with the unpacked arguments\n",
        "    response = tool_func(**arguments)\n",
        "\n",
        "    # Return the result of the function call, if any\n",
        "    if response:\n",
        "      return str(response)\n",
        "    else:\n",
        "      return \"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyOsu-4tleGP"
      },
      "source": [
        "## The agentic loop\n",
        "Instead of using a ready-made framework, the code below implements *direct orchestration*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydrbuU8oCta5"
      },
      "source": [
        "We want to build a `while True` loop with tool calls when the LLM requests it.  \n",
        "\n",
        "<img src=\"https://github.com/marta-manzin/agentic-shopping-assistant/blob/marta/images/agentic_flow.png?raw=1\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gixuOfxwCta5"
      },
      "source": [
        "`print_history` is a utility function that will display the LLM conversation history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tt5WwgxACta5"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def print_history(messages, width=70):\n",
        "    \"\"\"Pretty print messages history.\"\"\"\n",
        "    # For each message in the history\n",
        "    for i, msg in enumerate(messages):\n",
        "        print(f\"\\n[{i}] Role: {msg['role']}\")\n",
        "\n",
        "        # Display message text if present\n",
        "        if msg.get('content'):\n",
        "            for line in str(msg['content']).split('\\n'):\n",
        "                wrapped = textwrap.fill(line, width=width, initial_indent='    ', subsequent_indent='    ')\n",
        "                print(wrapped)\n",
        "\n",
        "        # Display tool calls if present\n",
        "        if msg.get('tool_calls'):\n",
        "            for tc in msg['tool_calls']:\n",
        "                func_name = tc.function.name\n",
        "                func_args = tc.function.arguments\n",
        "                print(f\"    üîß {func_name}({func_args})\")\n",
        "\n",
        "        # If this is an assistant message with no tool calls, show completion\n",
        "        if msg['role'] == 'assistant' and not msg.get('tool_calls'):\n",
        "            print(f\"\\n‚≠ê The resulting set is: {MY_SET}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4h6eNk8Cta5"
      },
      "source": [
        "Initialize the chat history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uMH41c0dCta5",
        "outputId": "65ac9932-5a4f-4c24-98d5-41637d51c406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[0] Role: system\n",
            "\n",
            "    You are a helpful assistant that adds and removes strings from a\n",
            "    set.\n",
            "\n",
            "    You have access to tools that let you:\n",
            "    1. Add a string, if it is not already in the set.\n",
            "    2. Remove a string.\n",
            "    3. Read all contents of the set.\n",
            "\n",
            "\n",
            "[1] Role: user\n",
            "    Please add 'apples' to the set.\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": SYSTEM_PROMPT\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Please add 'apples' to the set.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print_history(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask the agent what to do next."
      ],
      "metadata": {
        "id": "S0NHnlMuEg3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\"\n",
        ").choices[0].message\n",
        "\n",
        "# Display the raw tool call in the agent's response\n",
        "tool_calls_data = [tc.model_dump() for tc in response.tool_calls]\n",
        "print(json.dumps(tool_calls_data, indent=2))"
      ],
      "metadata": {
        "id": "2l5y9lDvEgGw",
        "outputId": "4546a006-3008-4200-c6da-dc8849d241de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"id\": \"call_QIceclrzqnpA3v7ej0lgwinV\",\n",
            "    \"function\": {\n",
            "      \"arguments\": \"{\\\"s\\\":\\\"apples\\\"}\",\n",
            "      \"name\": \"insertion_tool\"\n",
            "    },\n",
            "    \"type\": \"function\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35gElhhYCta5"
      },
      "source": [
        "Update the chat history with the agent's response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "sWBZcuurCta5",
        "outputId": "76c328d4-1181-4585-d0d9-23610c6b4601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[0] Role: system\n",
            "\n",
            "    You are a helpful assistant that adds and removes strings from a\n",
            "    set.\n",
            "\n",
            "    You have access to tools that let you:\n",
            "    1. Add a string, if it is not already in the set.\n",
            "    2. Remove a string.\n",
            "    3. Read all contents of the set.\n",
            "\n",
            "\n",
            "[1] Role: user\n",
            "    Please add 'apples' to the set.\n",
            "\n",
            "[2] Role: assistant\n",
            "    üîß insertion_tool({\"s\":\"apples\"})\n"
          ]
        }
      ],
      "source": [
        "messages.append({\n",
        "    \"role\": \"assistant\",\n",
        "    \"content\": response.content,\n",
        "    \"tool_calls\": response.tool_calls\n",
        "})\n",
        "\n",
        "print_history(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uudc001fCta6"
      },
      "source": [
        "Execute the tool call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9yMBxPNKCta6",
        "outputId": "d2422bb5-a402-456d-8001-143d07f5c83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Inserted 'apples'.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "MY_SET = set()\n",
        "\n",
        "outcome = execute(response.tool_calls[0])\n",
        "outcome"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A949_DYhCta6"
      },
      "source": [
        "Append the outcome to the message history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Zc5xXr7yCta6",
        "outputId": "3b31219c-2750-4f40-a9bc-345d1d753e8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[0] Role: system\n",
            "\n",
            "    You are a helpful assistant that adds and removes strings from a\n",
            "    set.\n",
            "\n",
            "    You have access to tools that let you:\n",
            "    1. Add a string, if it is not already in the set.\n",
            "    2. Remove a string.\n",
            "    3. Read all contents of the set.\n",
            "\n",
            "\n",
            "[1] Role: user\n",
            "    Please add 'apples' to the set.\n",
            "\n",
            "[2] Role: assistant\n",
            "    üîß insertion_tool({\"s\":\"apples\"})\n",
            "\n",
            "[3] Role: tool\n",
            "    Inserted 'apples'.\n"
          ]
        }
      ],
      "source": [
        "messages.append({\n",
        "    \"role\": \"tool\",\n",
        "    \"tool_call_id\": tool_call.id,\n",
        "    \"content\": str(outcome)\n",
        "})\n",
        "print_history(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUm6RwSVCta6"
      },
      "source": [
        "Combine all direct orchestration steps into one method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "u4B9C8CKXmOm"
      },
      "outputs": [],
      "source": [
        "def submit_request(\n",
        "    user_prompt: str,\n",
        "    verbose: bool = True\n",
        "    ):\n",
        "    \"\"\"Submit a request to the agent and run any tools it calls.\"\"\"\n",
        "    # Initialize the chat history\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    while True:\n",
        "\n",
        "        # Ask the agent what to do next\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            tool_choice=\"auto\"\n",
        "        ).choices[0].message\n",
        "\n",
        "        # Update the chat history with the agent's response\n",
        "        messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": response.content,\n",
        "            \"tool_calls\": response.tool_calls\n",
        "        })\n",
        "\n",
        "        # If agent did not call any tools, we are done\n",
        "        if not response.tool_calls:\n",
        "            if verbose:\n",
        "              print(f\"\\n‚≠ê The resulting set is: {MY_SET}\")\n",
        "            break\n",
        "\n",
        "        # Execute all tool calls\n",
        "        for tool_call in response.tool_calls:\n",
        "            if verbose:\n",
        "              print(f\"\\nüîß The agent is calling a tool: \"\n",
        "                  f\"{tool_call.function.name}\"\n",
        "                  f\"({json.loads(tool_call.function.arguments)})\")\n",
        "\n",
        "            # Append the outcome to the message history\n",
        "            outcome = execute(tool_call)\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"content\": str(outcome)\n",
        "            })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF26AUcTeM9C"
      },
      "source": [
        "## Let's test the agent!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcdl8b9sCta6"
      },
      "source": [
        "Submit a request to the agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfQWYK7ceHVY",
        "outputId": "9c354552-4013-40ce-deb3-74caf20c01ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß The agent is calling a tool: insertion_tool({'s': 'apples'})\n",
            "\n",
            "üîß The agent is calling a tool: insertion_tool({'s': 'oranges'})\n",
            "\n",
            "üîß The agent is calling a tool: insertion_tool({'s': 'pears'})\n",
            "\n",
            "‚≠ê The resulting set is: {'oranges', 'pears', 'apples'}\n"
          ]
        }
      ],
      "source": [
        "MY_SET = set()\n",
        "submit_request(\"Please add 'apples', 'oranges' and 'pears' to the set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyEnJNzACta6"
      },
      "source": [
        "Inspect the message history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnCP2npeeYev",
        "outputId": "7f582786-bf84-4616-abae-5a17da3bc8c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß The agent is calling a tool: removal_tool({'s': 'oranges'})\n",
            "\n",
            "‚≠ê The resulting set is: {'pears', 'apples'}\n"
          ]
        }
      ],
      "source": [
        "submit_request(\"Please remove 'oranges' from the set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_P3GEVCNTQ6"
      },
      "source": [
        "# üóÑÔ∏è Creating an MCP Server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD6I4qqM3-K-"
      },
      "source": [
        "Create the MCP server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xem5Szb0AQqv"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet mcp\n",
        "from mcp.server import Server\n",
        "from mcp.types import Tool, TextContent\n",
        "\n",
        "server = Server(\"set-server\")\n",
        "print(\"‚úì Server created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuRlZnAYATtj"
      },
      "source": [
        "Create an MCP wrapper for listing the available tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4RQ-E6QArjt"
      },
      "outputs": [],
      "source": [
        "async def list_tools() -> list[Tool]:\n",
        "    \"\"\"Return the list of available tools from our tools definition.\"\"\"\n",
        "    # Create an empty list to store MCP Tool objects\n",
        "    mcp_tools = []\n",
        "\n",
        "    # Convert each tool from our OpenAI format to MCP format\n",
        "    for tool_def in tools:\n",
        "        # Extract the function definition from the OpenAI tool format\n",
        "        func_def = tool_def[\"function\"]\n",
        "\n",
        "        # Create an MCP Tool object with the same information\n",
        "        mcp_tools.append(Tool(\n",
        "            name=func_def[\"name\"], # the function name\n",
        "            description=func_def[\"description\"], # what the tool does\n",
        "            inputSchema=func_def[\"parameters\"] # the JSON schema for parameters\n",
        "        ))\n",
        "\n",
        "    # Return the list of MCP Tool objects\n",
        "    return mcp_tools\n",
        "\n",
        "# Register the list_tools function with the server\n",
        "# This tells the MCP server to use this function when clients ask for available tools\n",
        "server.list_tools()(list_tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM4w_xtuAvHM"
      },
      "source": [
        "Create an MCP wrapper for executing tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib0oaEEQBJp2"
      },
      "outputs": [],
      "source": [
        "from types import SimpleNamespace\n",
        "\n",
        "async def call_tool(name: str, arguments: dict) -> list[TextContent]:\n",
        "    \"\"\"Handle MCP tool calls by delegating to our existing tools.\"\"\"\n",
        "    # Convert MCP format to the format expected by execute()\n",
        "    # execute() expects: tool_call.function.name and tool_call.function.arguments\n",
        "\n",
        "    # Create the inner function object with name and arguments\n",
        "    function = SimpleNamespace(\n",
        "        name=name,\n",
        "        arguments=json.dumps(arguments)  # Convert dict to JSON string\n",
        "    )\n",
        "\n",
        "    # Create the tool_call object with the function attribute\n",
        "    tool_call = SimpleNamespace(function=function)\n",
        "\n",
        "    # Execute the tool using our existing execute() function\n",
        "    result = execute(tool_call)\n",
        "\n",
        "    # Convert result to MCP response format\n",
        "    result_text = str(result) if result is not None else \"Success\"\n",
        "    return [TextContent(type=\"text\", text=result_text)]\n",
        "\n",
        "# Register the call_tool function with the server\n",
        "server.call_tool()(call_tool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_UTk9kMBXdv"
      },
      "source": [
        "Expose an HTTP/SSE endpoint for the server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ57ifFcBbDx"
      },
      "outputs": [],
      "source": [
        "# FastAPI is a framework for building REST APIs\n",
        "%pip install --quiet fastapi\n",
        "from mcp.server.sse import SseServerTransport\n",
        "from fastapi import FastAPI, Request\n",
        "from fastapi.responses import Response\n",
        "\n",
        "# Create an SSE transport that will handle messages at the \"/messages\" path\n",
        "sse = SseServerTransport(\"/messages\")\n",
        "\n",
        "# Create a FastAPI web application\n",
        "app = FastAPI()\n",
        "\n",
        "\n",
        "async def handle_sse(request: Request):\n",
        "    \"\"\"Handle incoming SSE connections from MCP clients.\"\"\"\n",
        "    # Connect the SSE transport to get read/write streams\n",
        "    async with sse.connect_sse(\n",
        "        request.scope, request.receive, request._send\n",
        "    ) as (read_stream, write_stream):\n",
        "        # Run the MCP server with these streams\n",
        "        await server.run(\n",
        "            read_stream,\n",
        "            write_stream,\n",
        "            server.create_initialization_options()\n",
        "        )\n",
        "    return Response()\n",
        "\n",
        "# Register the GET endpoint with the FastAPI app\n",
        "# Clients connect to http://host:port/sse to establish SSE connection\n",
        "app.add_api_route(\"/sse\", handle_sse, methods=[\"GET\"])\n",
        "\n",
        "# Mount the POST handler for receiving messages\n",
        "# Clients send messages to http://host:port/messages\n",
        "app.mount(\"/messages\", sse.handle_post_message)\n",
        "\n",
        "print(\"‚úì FastAPI app created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Sp7zRqBjV7"
      },
      "source": [
        "Start the MCP server in the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBOee8pYCta7"
      },
      "outputs": [],
      "source": [
        "# Uvicorn is a web server that handles HTTP requests and asynchronous code\n",
        "%pip install --quiet uvicorn\n",
        "import threading\n",
        "import uvicorn\n",
        "import sys\n",
        "import random\n",
        "\n",
        "# The port number where the server will listen\n",
        "server_port = random.randint(49152, 65535)\n",
        "\n",
        "def run_server():\n",
        "    \"\"\"Run the uvicorn server. This will be called in a background thread.\"\"\"\n",
        "    try:\n",
        "        # Start the server on all network interfaces (0.0.0.0) at the specified port\n",
        "        uvicorn.run(app, host=\"0.0.0.0\", port=server_port, log_level=\"warning\")\n",
        "    except Exception as e:\n",
        "        # Print any errors to stderr\n",
        "        print(f\"‚úó Server error: {e}\", file=sys.stderr)\n",
        "\n",
        "# Start server in background thread\n",
        "server_thread = threading.Thread(\n",
        "    target=run_server, # thread will automatically stop when main program exits\n",
        "    daemon=True\n",
        "  )\n",
        "server_thread.start()\n",
        "\n",
        "print(f\"‚úì Starting MCP HTTP server on port {server_port} in background...\")\n",
        "print(f\"  Server available at http://127.0.0.1:{server_port}/sse\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFpcTtJWB2-W"
      },
      "source": [
        "Verify that the server port is open and listening."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnEligIZB4qz"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import socket\n",
        "\n",
        "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "sock.settimeout(1)\n",
        "\n",
        "# Try up to 5 times to verify the server started successfully\n",
        "for attempt in range(1, 6):\n",
        "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    sock.settimeout(1)\n",
        "\n",
        "    try:\n",
        "        sock.connect((\"127.0.0.1\", server_port))\n",
        "        print(f\"‚úì Port {server_port} is open (attempt {attempt}/5)\")\n",
        "        sock.close()\n",
        "        break   # Exit the loop early since we confirmed the server is running\n",
        "    except:\n",
        "        print(f\"‚è≥ Attempt {attempt}/5: Port {server_port} not ready yet...\")\n",
        "        # Wait 1 second before trying again (unless this is the last attempt)\n",
        "        if attempt < 5:\n",
        "            time.sleep(1)\n",
        "\n",
        "else:\n",
        "    # This else block runs if we never broke out of the loop (all 5 attempts failed)\n",
        "    print(f\"‚úó Port {server_port} is not open after 5 attempts\")\n",
        "    print(\"Make sure the server is running (previous cell)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l0hKhJyCB7s"
      },
      "source": [
        "Test the server with a dummy client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "id": "QQk64JgCvFrP",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from mcp import ClientSession\n",
        "from mcp.client.sse import sse_client\n",
        "\n",
        "# Build the URL where our server is listening\n",
        "server_url = f\"http://127.0.0.1:{server_port}/sse\"\n",
        "\n",
        "async def test_client():\n",
        "    \"\"\"Test that the MCP server works by calling tools as a client.\"\"\"\n",
        "    # Connect to the server using SSE client\n",
        "    async with sse_client(server_url) as (read, write):\n",
        "        # Create a client session with the read/write streams\n",
        "        async with ClientSession(read, write) as session:\n",
        "            # Initialize the session (required handshake)\n",
        "            await session.initialize()\n",
        "\n",
        "            # List available tools from the server\n",
        "            available_tools = await session.list_tools()\n",
        "            print(\"Available tools:\", [t.name for t in available_tools.tools])\n",
        "\n",
        "            # Test the insertion_tool by adding 'cherries' to the set\n",
        "            print(\"\\nTesting insertion_tool with 'cherries':\")\n",
        "            result = await session.call_tool(\"insertion_tool\", {\"s\": \"cherries\"})\n",
        "            print(\"Result:\", result.content[0].text)\n",
        "            print(\"Current set:\", MY_SET)\n",
        "\n",
        "            # Test the removal_tool by removing 'cherries' from the set\n",
        "            print(\"\\nTesting removal_tool with 'cherries':\")\n",
        "            result = await session.call_tool(\"removal_tool\", {\"s\": \"cherries\"})\n",
        "            print(\"Result:\", result.content[0].text)\n",
        "            print(\"Current set:\", MY_SET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "KhPeCIVfCta7"
      },
      "outputs": [],
      "source": [
        "# I had to separate out the runing of the async functions at the top level because what works in jupyter\n",
        "# doesn't work in straight python.  And vice versa.  I will remove the day before class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [
          "active-ipynb"
        ],
        "id": "oKaeNsn3Cta8"
      },
      "outputs": [],
      "source": [
        "# Run the async test function\n",
        "await test_client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "raw_mimetype": "",
        "tags": [],
        "id": "lAlQCD9aCta8"
      },
      "outputs": [],
      "source": [
        "# py version\n",
        "import asyncio\n",
        "if IN_COLAB:\n",
        "    asyncio.run(test_client())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "hhA0L8dUNvYJ",
        "tags": []
      },
      "source": [
        "# üß† Orchestration with LangGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrIbDfYJN3y0"
      },
      "outputs": [],
      "source": [
        "%pip uninstall -y -qqq langchain\n",
        "%pip install --quiet \"langchain-openai>=0.2,<1.0\" \"langchain_mcp_adapters\" \"langgraph\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "id": "5x5y8R-nkMrq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "# Create MCP client that connects to your set-server\n",
        "client = MultiServerMCPClient(\n",
        "    {\n",
        "        \"set-server\": {\n",
        "            \"transport\": \"sse\",\n",
        "            \"url\": f\"http://localhost:{server_port}/sse\",\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [
          "active-ipynb"
        ],
        "id": "9LLjQytBCta8"
      },
      "outputs": [],
      "source": [
        "# Get available tools from the MCP server\n",
        "tools_from_mcp = await client.get_tools()\n",
        "print(f\"‚úì Loaded {len(tools_from_mcp)} tools from MCP server\")\n",
        "for tool in tools_from_mcp:\n",
        "    print(f\"  - {tool.name}: {tool.description}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "JvVsa-VmCta8"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    tools_from_mcp = asyncio.run(client.get_tools())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "id": "t_p_I0JokOjL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Create a LangGraph agent using the tools we already loaded\n",
        "agent_executor = create_react_agent(\n",
        "    ChatOpenAI(model=\"gpt-4o\", temperature=0),\n",
        "    tools_from_mcp,\n",
        ")\n",
        "\n",
        "print(\"‚úì LangGraph agent created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [
          "active-ipynb"
        ],
        "id": "0eKr2OgVCta8"
      },
      "outputs": [],
      "source": [
        "result = await agent_executor.ainvoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Please add 'grapes', 'kiwi', and 'mango' to the set.\"}]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "kbbM37aqCta8"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    result = asyncio.run(\n",
        "        agent_executor.ainvoke({\n",
        "            \"messages\": [{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"Please add 'grapes', 'kiwi', and 'mango' to the set.\"}]\n",
        "        })\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "id": "7zu7HEPAkQlc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Display the conversation\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "\n",
        "for message in result['messages']:\n",
        "    if isinstance(message, HumanMessage):\n",
        "        print(\"Human: \\033[32m\" + message.content + \"\\033[0m\")\n",
        "    elif isinstance(message, AIMessage):\n",
        "        if message.content:\n",
        "            print(\"AI: \\033[34m\" + message.content + \"\\033[0m\")\n",
        "    elif isinstance(message, ToolMessage):\n",
        "        if \"Error\" not in message.content:\n",
        "            print(f\"Tool Result: \\033[32mSuccess\\033[0m\")\n",
        "\n",
        "print(f\"\\n‚≠ê The resulting set is: {MY_SET}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "K0Cw_2GpvqKp",
        "tags": []
      },
      "source": [
        "# üßπ Cleanup\n",
        "\n",
        "Stop the MCP server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kTywUxOwKua"
      },
      "outputs": [],
      "source": [
        "# Kill any process running uvicorn on our server port\n",
        "!pkill -f \"uvicorn.*{server_port}\"\n",
        "print(\"‚úì Server stopped\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvwl7EKJTZSL"
      },
      "source": [
        "# Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "H4N9Oqg7No6i",
        "tags": []
      },
      "source": [
        "###"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "jupytext": {
      "cell_metadata_filter": "tags,id,outputId,raw_mimetype,colab_type,-editable,-slideshow,-colab",
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}